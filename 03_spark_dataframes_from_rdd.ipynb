{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"DF from RDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SPARK DATAFRAMES AND SQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating an RDD and transforming it into Dataframe: Reflection Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clines = sc.textFile(\"customers.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfields = clines.map(lambda line : line.split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = cfields.map(lambda values : Row(cid=int(values[0]), cname=values[1], ccity=values[2], cstate=values[3], czip=values[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = spark.createDataFrame(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating an RDD and transforming it into Dataframe: Programmatic Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers2 = cfields.map(lambda values : (values[0], values[1], values[2], values[3], values[4]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"cid cname ccity cstate czip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "columns = [StructField(column_name, StringType()) for column_name in schema.split()]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalschema = StructType(columns)\n",
    "finalschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf2 = spark.createDataFrame(customers2,finalschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+-------------+------+-----+\n",
      "|  cid|           cname|        ccity|cstate| czip|\n",
      "+-----+----------------+-------------+------+-----+\n",
      "|11039|     Mary Torres|       Caguas|    PR|  725|\n",
      "| 5623|      Jose Haley|     Columbus|    OH|43207|\n",
      "| 5829|      Mary Smith|      Houston|    TX|77015|\n",
      "| 6336|  Richard Maddox|       Caguas|    PR|  725|\n",
      "| 1708|  Margaret Booth|    Arlington|    TX|76010|\n",
      "|10227|  Mary Henderson|       Caguas|    PR|  725|\n",
      "|  839|     Lisa Walker|       Caguas|    PR|  725|\n",
      "| 7604|   Jonathan Hill|      Phoenix|    AZ|85040|\n",
      "| 6485|Carolyn Sheppard|Pompano Beach|    FL|33063|\n",
      "| 4737|    Mary Mendoza|       Caguas|    PR|  725|\n",
      "| 5973|   Michael Smith|       Caguas|    PR|  725|\n",
      "| 9205|    James Holmes|     Hilliard|    OH|43026|\n",
      "|  138|     Mary Dawson|       Caguas|    PR|  725|\n",
      "|  371|    Adam Marquez|  San Antonio|    TX|78223|\n",
      "| 9285|    Gloria Smith|       Caguas|    PR|  725|\n",
      "| 1209|       Mary Webb|   San Marcos|    TX|78666|\n",
      "| 3021|  Nancy Alvarado|     Flushing|    NY|11354|\n",
      "| 3354|  Russell Flores|       Caguas|    PR|  725|\n",
      "|11684|    Denise Smith|    Rego Park|    NY|11374|\n",
      "|11144|  Jose Dickerson|         Mesa|    AZ|85201|\n",
      "+-----+----------------+-------------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
